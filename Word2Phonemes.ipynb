{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "PhonemeToGrapheme.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhuwQ7OLzEHB",
        "colab_type": "text"
      },
      "source": [
        "# Words to Phonemes\n",
        "## A Machine Learning model that is able to translate written english words to their corresponding Phonemes.\n",
        "\n",
        "This Machine Learning algorithm has the objective of creating a Sequence-To-Sequence NLP model that is capable of translating a word input to its corresponding phonemes in the *arpabet* format.\n",
        "\n",
        "For example, it is able to receive the word \"car\" and return the phonemes \"K AA R\".\n",
        "\n",
        "It uses the Keras library to create an LSTM Recurrent Neural Network to be trained with thousands of english words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8ncd6Kn4WdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIdbIGdcaIlL",
        "colab_type": "text"
      },
      "source": [
        "### Training Data\n",
        "The Training Data is gathered from the [CMUDict](http://www.speech.cs.cmu.edu/cgi-bin/cmudict)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkhRuTRv4-1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "370aa302-aaf4-44fb-d765-2eea597ce961"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/microsoft/CNTK/v2.0/Examples/SequenceToSequence/CMUDict/Data/cmudict-0.7b.train\n",
        "\n",
        "#Open Text File\n",
        "f = open(\"cmudict-0.7b.train\", \"r\")\n",
        "dataString = f.read()\n",
        "\n",
        "# Seperate it into lines\n",
        "lines = dataString.split('\\n')\n",
        "\n",
        "# Shuffle\n",
        "random.shuffle(lines)\n",
        "lines[:4]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-30 14:42:53--  https://raw.githubusercontent.com/microsoft/CNTK/v2.0/Examples/SequenceToSequence/CMUDict/Data/cmudict-0.7b.train\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2851082 (2.7M) [text/plain]\n",
            "Saving to: ‘cmudict-0.7b.train.7’\n",
            "\n",
            "\rcmudict-0.7b.train.   0%[                    ]       0  --.-KB/s               \rcmudict-0.7b.train. 100%[===================>]   2.72M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-03-30 14:42:54 (33.7 MB/s) - ‘cmudict-0.7b.train.7’ saved [2851082/2851082]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SYNONYMOUS  S AH N AA N AH M AH S',\n",
              " 'EDITORIALIZING  EH D AH T AO R IY AH L AY Z IH NG',\n",
              " \"WINNER'S  W IH N ER Z\",\n",
              " 'DELMONT  D EY L M OW N T']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUW35P0GayOg",
        "colab_type": "text"
      },
      "source": [
        "After downloading, we need to prepare it. \n",
        "\n",
        "By iterating over each line of the document, the algorithm fills out two Arrays containing all of the work-phoneme pairs and two Sets containing every used character or phoneme, creating the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnMsoxpU4WdW",
        "colab_type": "code",
        "outputId": "b3778488-3e4d-4303-fab1-9a73c9f18d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Input and Target Arrays\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "#Vocabulary\n",
        "input_characters = set()\n",
        "target_phonemes = set()\n",
        "\n",
        "#Iterate over the lines\n",
        "for line in lines:\n",
        "    if line != \"\":\n",
        "      # Get the input word and the Target Phoneme\n",
        "      input_text, target_text = line.split('  ')\n",
        "\n",
        "      # TAB is the Start Character\n",
        "      # '\\n' is the End Chatachter\n",
        "      target_text = '\\t ' + target_text + ' \\n'\n",
        "\n",
        "      #Add the data to the Input and Target arrays\n",
        "      input_texts.append(input_text)\n",
        "      target_texts.append(target_text)\n",
        "\n",
        "      #Add new characters and phonemes to the vocabulary\n",
        "      for char in input_text:\n",
        "          if char not in input_characters:\n",
        "              input_characters.add(char)\n",
        "      for phoneme in target_text.split(\" \"):\n",
        "          if phoneme not in target_phonemes:\n",
        "              target_phonemes.add(phoneme)\n",
        "            \n",
        "# Sort the Vocabulary\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_phonemes = sorted(list(target_phonemes))\n",
        "\n",
        "# Usefeull property variables\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_phonemes)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt.split(\" \")) for txt in target_texts])\n",
        "num_samples = len(input_texts)\n",
        "\n",
        "print('Number of samples:', num_samples)\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 114399\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 41\n",
            "Max sequence length for inputs: 22\n",
            "Max sequence length for outputs: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8kYezzIcYzy",
        "colab_type": "text"
      },
      "source": [
        "Next, we create a Dictionary that pairs each Carachter and Phoneme to a corresponging number index.\n",
        "\n",
        "Ex: A --> 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiaOPUM84Wdc",
        "colab_type": "code",
        "outputId": "1231603a-0e13-4c57-c39e-92ae0e8da706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(phoneme, i) for i, phoneme in enumerate(target_phonemes)])\n",
        "\n",
        "input_token_index['A']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QWUpqjVdIxy",
        "colab_type": "text"
      },
      "source": [
        "### The Machine Learning Model\n",
        "Since this model is \"Sequence-to-Sequence\", it will receive a large list as input. \n",
        "\n",
        "This list, is the size of the entire training data **X** the largest input word's length **X** the size of the Output (Phoneme) Vocabulary.\n",
        "\n",
        "Therefore, the first step is to initialize this Array with only Zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nonxJDdM4Wdf",
        "colab_type": "code",
        "outputId": "38790f43-8d1e-43de-e802-9f20a28923f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Initiate all entrences and outputs in the initial state\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "encoder_input_data[:2]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pcG-kGQe0_B",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to fill the Array with the correct corresponding values.\n",
        "\n",
        "The value **1** will be placed at:\n",
        "- The index of the word inside the training data.\n",
        "- The index of the Character/Phoneme inside the word.\n",
        "- The index of the Character/Phoneme inside the Vocabulary.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RAGIVvm4Wdi",
        "colab_type": "code",
        "outputId": "f7a5f31b-6eef-4e8d-f0f9-82ec34299b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "# Iterate over touples of input and target to gererate the decoder and encoder input data\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "\n",
        "    # for every character in input text\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1. ## Bag of Letters\n",
        "    \n",
        "    # for every phoneme in target text\n",
        "    for t, phoneme in enumerate(target_text.split(\" \")):\n",
        "        # decoder_target_data is one step ahead of decoder_input_data\n",
        "        decoder_input_data[i, t, target_token_index[phoneme]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start phoneme.\n",
        "            decoder_target_data[i, t - 1, target_token_index[phoneme]] = 1.\n",
        "        \n",
        "encoder_input_data[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi9tuG6RgCFK",
        "colab_type": "text"
      },
      "source": [
        "####  ENCODER\n",
        "The first part of this sequence-to-sequence Machine Learning Model is an LSTM network used to encode the previously created 3D input matrix into data that will be latter used by the Decoder network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUD0SmxQ4WdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 30  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARxq2co64Wdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "dbc771e8-61bc-4bca-ce5b-e9a9e3122451"
      },
      "source": [
        "# Define an input sequence\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "\n",
        "# Create the Encoder LSTM\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "\n",
        "# Use the LSTM to fill out the encoder output and middle states.\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# For the decoder, only the middle states will be necessary.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlTIwBClhko5",
        "colab_type": "text"
      },
      "source": [
        "####  DECODER\n",
        "The next step in the model is creating a Decoding LSTM network that receives the previous state generated by the Encoder to generate the final correct output sequence, translating the characters into phonemes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko66R_Gf4Wdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Define an input sequence.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# Creathe the Decoder LSTM\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "# Use the LSTM to fill out the decoder Output\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# Create the Dense layer and use it to update the decoder output\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqSVOrwcsbpD",
        "colab_type": "text"
      },
      "source": [
        "### Model\n",
        "Now, we ca create the Model that will convert the input data from the encoder (and its generated decoder input) into the target output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ryCxbgj4Wdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the Model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVWS2HSws53L",
        "colab_type": "text"
      },
      "source": [
        "### Training\n",
        "Now its time to train out Model! It will run with the previously established configurations and input data for 30 epochs (aproximately 30 minutes).\n",
        "\n",
        "It uses the RMSProf optimizer and utilizes accurary as its metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClccLvhm4Wdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca913f0e-0d4a-4373-de0f-6cd9427466b2"
      },
      "source": [
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "\n",
        "# Save model\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 91519 samples, validate on 22880 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "91519/91519 [==============================] - 96s 1ms/step - loss: 0.7394 - acc: 0.1220 - val_loss: 0.5849 - val_acc: 0.1608\n",
            "Epoch 2/30\n",
            "91519/91519 [==============================] - 87s 953us/step - loss: 0.4696 - acc: 0.1919 - val_loss: 0.3564 - val_acc: 0.2241\n",
            "Epoch 3/30\n",
            "91519/91519 [==============================] - 87s 954us/step - loss: 0.2993 - acc: 0.2400 - val_loss: 0.2599 - val_acc: 0.2509\n",
            "Epoch 4/30\n",
            "91519/91519 [==============================] - 86s 938us/step - loss: 0.2188 - acc: 0.2639 - val_loss: 0.1980 - val_acc: 0.2705\n",
            "Epoch 5/30\n",
            "91519/91519 [==============================] - 86s 936us/step - loss: 0.1736 - acc: 0.2776 - val_loss: 0.1644 - val_acc: 0.2809\n",
            "Epoch 6/30\n",
            "91519/91519 [==============================] - 86s 940us/step - loss: 0.1448 - acc: 0.2866 - val_loss: 0.1456 - val_acc: 0.2862\n",
            "Epoch 7/30\n",
            "91519/91519 [==============================] - 90s 979us/step - loss: 0.1249 - acc: 0.2926 - val_loss: 0.1301 - val_acc: 0.2915\n",
            "Epoch 8/30\n",
            "91519/91519 [==============================] - 87s 954us/step - loss: 0.1103 - acc: 0.2972 - val_loss: 0.1226 - val_acc: 0.2935\n",
            "Epoch 9/30\n",
            "91519/91519 [==============================] - 89s 975us/step - loss: 0.0990 - acc: 0.3008 - val_loss: 0.1146 - val_acc: 0.2959\n",
            "Epoch 10/30\n",
            "91519/91519 [==============================] - 89s 968us/step - loss: 0.0897 - acc: 0.3036 - val_loss: 0.1115 - val_acc: 0.2971\n",
            "Epoch 11/30\n",
            "91519/91519 [==============================] - 88s 960us/step - loss: 0.0823 - acc: 0.3058 - val_loss: 0.1081 - val_acc: 0.2985\n",
            "Epoch 12/30\n",
            "91519/91519 [==============================] - 87s 949us/step - loss: 0.0756 - acc: 0.3080 - val_loss: 0.1053 - val_acc: 0.2995\n",
            "Epoch 13/30\n",
            "91519/91519 [==============================] - 88s 960us/step - loss: 0.0700 - acc: 0.3098 - val_loss: 0.1046 - val_acc: 0.3001\n",
            "Epoch 14/30\n",
            "91519/91519 [==============================] - 87s 949us/step - loss: 0.0651 - acc: 0.3113 - val_loss: 0.1027 - val_acc: 0.3009\n",
            "Epoch 15/30\n",
            "91519/91519 [==============================] - 88s 956us/step - loss: 0.0607 - acc: 0.3127 - val_loss: 0.1063 - val_acc: 0.3004\n",
            "Epoch 16/30\n",
            "91519/91519 [==============================] - 87s 946us/step - loss: 0.0566 - acc: 0.3141 - val_loss: 0.1033 - val_acc: 0.3016\n",
            "Epoch 17/30\n",
            "91519/91519 [==============================] - 87s 953us/step - loss: 0.0532 - acc: 0.3152 - val_loss: 0.1056 - val_acc: 0.3013\n",
            "Epoch 18/30\n",
            "91519/91519 [==============================] - 87s 956us/step - loss: 0.0500 - acc: 0.3163 - val_loss: 0.1055 - val_acc: 0.3018\n",
            "Epoch 19/30\n",
            "91519/91519 [==============================] - 87s 949us/step - loss: 0.0470 - acc: 0.3172 - val_loss: 0.1053 - val_acc: 0.3019\n",
            "Epoch 20/30\n",
            "91519/91519 [==============================] - 87s 951us/step - loss: 0.0444 - acc: 0.3181 - val_loss: 0.1071 - val_acc: 0.3014\n",
            "Epoch 21/30\n",
            "91519/91519 [==============================] - 86s 942us/step - loss: 0.0419 - acc: 0.3190 - val_loss: 0.1075 - val_acc: 0.3020\n",
            "Epoch 22/30\n",
            "91519/91519 [==============================] - 87s 946us/step - loss: 0.0398 - acc: 0.3197 - val_loss: 0.1096 - val_acc: 0.3018\n",
            "Epoch 23/30\n",
            "91519/91519 [==============================] - 86s 936us/step - loss: 0.0379 - acc: 0.3203 - val_loss: 0.1106 - val_acc: 0.3021\n",
            "Epoch 24/30\n",
            "91519/91519 [==============================] - 86s 936us/step - loss: 0.0360 - acc: 0.3210 - val_loss: 0.1130 - val_acc: 0.3021\n",
            "Epoch 25/30\n",
            "91519/91519 [==============================] - 88s 956us/step - loss: 0.0344 - acc: 0.3216 - val_loss: 0.1133 - val_acc: 0.3023\n",
            "Epoch 26/30\n",
            "91519/91519 [==============================] - 87s 954us/step - loss: 0.0330 - acc: 0.3220 - val_loss: 0.1147 - val_acc: 0.3020\n",
            "Epoch 27/30\n",
            "91519/91519 [==============================] - 86s 941us/step - loss: 0.0316 - acc: 0.3225 - val_loss: 0.1158 - val_acc: 0.3021\n",
            "Epoch 28/30\n",
            "91519/91519 [==============================] - 87s 946us/step - loss: 0.0304 - acc: 0.3229 - val_loss: 0.1163 - val_acc: 0.3023\n",
            "Epoch 29/30\n",
            "91519/91519 [==============================] - 87s 952us/step - loss: 0.0294 - acc: 0.3233 - val_loss: 0.1185 - val_acc: 0.3023\n",
            "Epoch 30/30\n",
            "91519/91519 [==============================] - 87s 951us/step - loss: 0.0285 - acc: 0.3236 - val_loss: 0.1188 - val_acc: 0.3020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_zz2Y8Pu-iK",
        "colab_type": "text"
      },
      "source": [
        "### Testing\n",
        "Let's test our trained model! First, we create a sampling encoder and decoder models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC2-KqDs4Wd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01f293f5-10da-4818-f50c-1bf9e8aab034"
      },
      "source": [
        "# Create Encoder Sampling Model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Define decoder inputs\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Generate decoder outputs by using the trained dense layer\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Create Decoder Sampling Model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdiV_d5Fvu9P",
        "colab_type": "text"
      },
      "source": [
        "Create a Dictionary to reverse-lookup the index into its respective character or phoneme.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND5WTeKC4Wd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Character reverse look-up\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "\n",
        "# Phoneme reverse look-up\n",
        "reverse_target_phoneme_index = dict(\n",
        "    (i, phoneme) for phoneme, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS8-TdLKxOLp",
        "colab_type": "text"
      },
      "source": [
        "Now, we need a function that receives the input sequence and returns the decoded word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6dlmLM-FMPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Get the encoder model prediction\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate an empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "\n",
        "    # Set the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Now, we need to iterate over the sequence until we find the stop character\n",
        "    stop_condition = False\n",
        "    decoded_word = ''\n",
        "    while not stop_condition:\n",
        "        # Get the decoder model prediction\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Get the sampled phoneme and add it to the decoded word\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_phoneme = reverse_target_phoneme_index[sampled_token_index]\n",
        "        decoded_word += sampled_phoneme + \" \"\n",
        "\n",
        "        # Exit the loop if \\n is fount or if the decoded word is larger then the maximum permited size.\n",
        "        if (sampled_phoneme == '\\n' or\n",
        "           len(decoded_word) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    # Return the decoded word\n",
        "    return decoded_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyifNUEZzryS",
        "colab_type": "text"
      },
      "source": [
        "Now, to test on any input value, we create a function that receives a word, converts it into a sequence an then decodes it with our previous function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNiNcnjVFms4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPhonemes(word):\n",
        "  #make the input uppercase\n",
        "  word = word.upper()\n",
        "\n",
        "  # Initialize the input sequence with only zeros.\n",
        "  myInput = np.zeros(\n",
        "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
        "      dtype='float32')\n",
        "\n",
        "  # Fill the sequence correctly with the word\n",
        "  for t, char in enumerate(word):\n",
        "      myInput[0, t, input_token_index[char]] = 1.\n",
        "\n",
        "  # Return the decoded value\n",
        "  return decode_sequence(myInput).replace('\\n', '').replace('\\t', '').replace('  ', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apZos5Uz0l4F",
        "colab_type": "text"
      },
      "source": [
        "We can now call the function with any word (that was not even in the training dataset) to see its predicted phonetic separation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqD2B4p_IAYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2f5f056-f488-4378-cc1d-b3c5ad9f6402"
      },
      "source": [
        "getPhonemes(\"trailer\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T R EY L ER'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3V5_7CQy71a",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can itarete over some values in a test dataset and see its corresponding results and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIFUBBPRFRL2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "ab47a377-5186-4ff0-f635-8de5b3d55867"
      },
      "source": [
        "# Download the Test Dataset\n",
        "!wget https://raw.githubusercontent.com/microsoft/CNTK/v2.0/Examples/SequenceToSequence/CMUDict/Data/cmudict-0.7b.test\n",
        "\n",
        "# Separate the data into shuffled lines\n",
        "f = open(\"cmudict-0.7b.train\", \"r\")\n",
        "dataString = f.read()\n",
        "words_phonemes = dataString.split('\\n')\n",
        "random.shuffle(words_phonemes)\n",
        "\n",
        "size = 4\n",
        "correct = 0\n",
        "\n",
        "for seq_index in range(size):\n",
        "    # Get an input from the encoder's input.\n",
        "    word_phoneme = words_phonemes[seq_index].split('  ')\n",
        "    word = word_phoneme[0]\n",
        "    correct_phoneme = word_phoneme[1]\n",
        "\n",
        "    #Have the word be decoded\n",
        "    decoded_phoneme= getPhonemes(word)\n",
        "\n",
        "    #Update the number of correct translations\n",
        "    if decoded_phoneme == correct_phoneme:\n",
        "      correct += 1\n",
        "\n",
        "    #Print the results\n",
        "    print('-')\n",
        "    print('Input Word:', word)\n",
        "    print('Decoded Phonemes:', decoded_phoneme)\n",
        "    print('Actual Phonemes:', correct_phoneme)\n",
        "\n",
        "print('Correctly answered ', correct, ' out of ', size)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-30 15:33:19--  https://raw.githubusercontent.com/microsoft/CNTK/v2.0/Examples/SequenceToSequence/CMUDict/Data/cmudict-0.7b.test\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 321219 (314K) [text/plain]\n",
            "Saving to: ‘cmudict-0.7b.test.3’\n",
            "\n",
            "\rcmudict-0.7b.test.3   0%[                    ]       0  --.-KB/s               \rcmudict-0.7b.test.3 100%[===================>] 313.69K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-03-30 15:33:19 (20.3 MB/s) - ‘cmudict-0.7b.test.3’ saved [321219/321219]\n",
            "\n",
            "-\n",
            "Input Word: NASHUA\n",
            "Decoded Phonemes: N AE SH UW AH\n",
            "Actual Phonemes: N AE SH UW AH\n",
            "-\n",
            "Input Word: PRIED\n",
            "Decoded Phonemes: P R AY D\n",
            "Actual Phonemes: P R AY D\n",
            "-\n",
            "Input Word: WHISKERS\n",
            "Decoded Phonemes: W IH S K ER Z\n",
            "Actual Phonemes: W IH S K ER Z\n",
            "-\n",
            "Input Word: FERRONICKEL\n",
            "Decoded Phonemes: F EH R AH N IH K AH L\n",
            "Actual Phonemes: F EH R AH N IH K AH L\n",
            "Correctly answered  4  out of  4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}